defaultRules:
  labels:
    cluster: "$CLUSTER_NAME"
    foundation: "$FOUNDATION"

commonLabels:
  cluster: "$CLUSTER_NAME"
  foundation: "$FOUNDATION"

alertmanager:
  config:
    global:
      resolve_timeout: 5m
    route:
      group_by: ['alertname']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'email'
      routes:
      - match:
          alertname: Watchdog
        receiver: 'null'
      - match:
          alertname: TestAlert
        receiver: 'email'
    receivers:
    - name: 'null'
    - name: 'email'
      email_configs:
      - to: $GMAIL_ACCOUNT
        from: $GMAIL_ACCOUNT
        smarthost: "smtp.gmail.com:587"
        auth_username: "$GMAIL_ACCOUNT"
        auth_identity: "$GMAIL_ACCOUNT"
        auth_password: "$GMAIL_AUTH_TOKEN"

prometheus:
  prometheusSpec:
    podAntiAffinity: "hard"
    secrets:
      - etcd-client
    ruleSelector:
      matchLabels:
        app: prometheus-operator
        release: monitoring
    enableAdminAPI: true
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: thin-disk
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 5Gi
        selector:
          matchExpressions:
            - key: app
              operator: In
              values:
                - prometheus
                - bosh-exporter

grafana:
  notifiers: 
    notifiers.yaml:
      notifiers:
      - name: email-notifier
        type: email
        uid: email1
        org_id: 1
        is_default: true
        settings:
          addresses: "$GMAIL_ACCOUNT"

  smtp:
    existingSecret: "smtp-creds"
    userKey: "user"
    passwordKey: "password"

  grafana.ini:
    smtp:
      enabled: true
      userKey: "user"
      passwordKey: "password"
      host: "smtp.gmail.com:587"

additionalPrometheusRulesMap:
  testing:
    groups:
    - name: test-alerting.rules
      rules:
      - alert: TestAlert
        annotations:
          message: The disk {{`{{ $labels.instance }}`}} running on {{`{{ $labels.cluster }}`}} in {{`{{ $labels.foundation }}`}} is running full.
        expr: vector(1)
        for: 1m
        labels:
          severity: critical

kubeApiServer:
  # Stupid helm chart put this in the wrong place!
  relabelings:
  - action: replace
    sourceLabels: [__meta_kubernetes_service_label_cluster]
    regex: '(.*)'
    targetLabel: cluster
    replacement: '${1}'
  - action: replace
    sourceLabels: [__meta_kubernetes_service_label_foundation]
    regex: '(.*)'
    targetLabel: foundation
    replacement: '${1}'
  serviceMonitor:
    interval: 30s
    metricRelabelings:
    - action: drop
      regex: etcd_(debugging|disk|request|server).*
      sourceLabels:
      - __name__
    - action: drop
      regex: apiserver_admission_controller_admission_latencies_seconds_.*
      sourceLabels:
      - __name__
    - action: drop
      regex: apiserver_admission_step_admission_latencies_seconds_.*
      sourceLabels:
      - __name__

kubeControllerManager:
  endpoints: ${ENDPOINTS}
  serviceMonitor:
    interval: 30s
    insecureSkipVerify: true
    relabelings:
    - sourceLabels: [__meta_kubernetes_service_label_cluster]
      regex: '(.*)'
      targetLabel: cluster
      replacement: '${1}'
    - sourceLabels: [__meta_kubernetes_service_label_foundation]
      regex: '(.*)'
      targetLabel: foundation
      replacement: '${1}'
    metricRelabelings:
    - action: drop
      regex: etcd_(debugging|disk|request|server).*
      sourceLabels:
      - __name__

kubeScheduler:
  endpoints: ${ENDPOINTS}
  serviceMonitor:
    interval: 30s
    insecureSkipVerify: true
    relabelings:
    - sourceLabels: [__meta_kubernetes_service_label_cluster]
      regex: '(.*)'
      targetLabel: cluster
      replacement: '${1}'
    - sourceLabels: [__meta_kubernetes_service_label_foundation]
      regex: '(.*)'
      targetLabel: foundation
      replacement: '${1}'
